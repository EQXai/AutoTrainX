# AutoTrainX Training Log
# Dataset: m14w00dh4ll
# Preset: SX1
# Job ID: 1e0cccac
# Start Time: 2025-08-02T17:33:09.569918
# Mode: single
# Command: /home/eqx/AutoTrainX/venv/bin/python /home/eqx/AutoTrainX/sd-scripts/sdxl_train.py --config_file /home/eqx/AutoTrainX/workspace/Presets/m14w00dh4ll_SX1_1e0cccac.toml --max_grad_norm=0.0 --no_half_vae --train_text_encoder --learning_rate_te2=0
================================================================================

2025-08-02 17:33:13 INFO     Loading settings from                                                           train_util.py:4651
                             /home/eqx/AutoTrainX/workspace/Presets/m14w00dh4ll_SX1_1e0cccac.toml...                           
                    WARNING  clip_skip will be unexpected / SDXL学習ではclip_skipは動作しません          sdxl_train_util.py:349
2025-08-02 17:33:13 INFO     Using DreamBooth method.                                                         sdxl_train.py:153
                    INFO     prepare images.                                                                 train_util.py:2072
                    INFO     get image size from name of cache files                                         train_util.py:1965

  0%|          | 0/3 [00:00<?, ?it/s]
100%|██████████| 3/3 [00:00<00:00, 112347.43it/s]
                    INFO     set image size from cache files: 0/3                                            train_util.py:1995
                    INFO     found directory                                                                 train_util.py:2019
                             /home/eqx/AutoTrainX/workspace/output/m14w00dh4ll/img/30_m14w00dh4ll person                       
                             contains 3 image files                                                                            

read caption:   0%|          | 0/3 [00:00<?, ?it/s]
read caption: 100%|██████████| 3/3 [00:00<00:00, 31615.36it/s]
                    INFO     90 train images with repeats.                                                   train_util.py:2116
                    INFO     0 reg images with repeats.                                                      train_util.py:2120
                    WARNING  no regularization images / 正則化画像が見つかりませんでした                     train_util.py:2125
                    INFO     [Dataset 0]                                                                     config_util.py:580
                               batch_size: 2                                                                                   
                               resolution: (1024, 1280)                                                                        
                               resize_interpolation: None                                                                      
                               enable_bucket: False                                                                            
                                                                                                                               
                               [Subset 0 of Dataset 0]                                                                         
                                 image_dir:                                                                                    
                             "/home/eqx/AutoTrainX/workspace/output/m14w00dh4ll/img/30_m14w00dh4ll person"                     
                                 image_count: 3                                                                                
                                 num_repeats: 30                                                                               
                                 shuffle_caption: False                                                                        
                                 keep_tokens: 0                                                                                
                                 caption_dropout_rate: 0                                                                       
                                 caption_dropout_every_n_epochs: 0                                                             
                                 caption_tag_dropout_rate: 0.0                                                                 
                                 caption_prefix: None                                                                          
                                 caption_suffix: None                                                                          
                                 color_aug: False                                                                              
                                 flip_aug: False                                                                               
                                 face_crop_aug_range: None                                                                     
                                 random_crop: False                                                                            
                                 token_warmup_min: 1,                                                                          
                                 token_warmup_step: 0,                                                                         
                                 alpha_mask: False                                                                             
                                 resize_interpolation: None                                                                    
                                 custom_attributes: {}                                                                         
                                 is_reg: False                                                                                 
                                 class_tokens: m14w00dh4ll person                                                              
                                 caption_extension: .txt                                                                       
                                                                                                                               
                                                                                                                               
                    INFO     [Prepare dataset 0]                                                             config_util.py:592
                    INFO     loading image sizes.                                                             train_util.py:987

  0%|          | 0/3 [00:00<?, ?it/s]
100%|██████████| 3/3 [00:00<00:00, 30467.10it/s]
                    INFO     prepare dataset                                                                 train_util.py:1012
                    INFO     prepare accelerator                                                              sdxl_train.py:211
                    INFO     loading model for process 0/1                                                sdxl_train_util.py:32
                    INFO     load StableDiffusion checkpoint:                                             sdxl_train_util.py:73
                             /home/eqx/AutoTrainX/models/SDXLModel.safetensors                                                 
                    INFO     building U-Net                                                              sdxl_model_util.py:198
2025-08-02 17:33:14 INFO     loading U-Net from checkpoint                                               sdxl_model_util.py:202
2025-08-02 17:33:15 INFO     U-Net: <All keys matched successfully>                                      sdxl_model_util.py:208
                    INFO     building text encoders                                                      sdxl_model_util.py:211
                    INFO     loading text encoders from checkpoint                                       sdxl_model_util.py:264
                    INFO     text encoder 1: <All keys matched successfully>                             sdxl_model_util.py:278
2025-08-02 17:33:16 INFO     text encoder 2: <All keys matched successfully>                             sdxl_model_util.py:282
                    INFO     building VAE                                                                sdxl_model_util.py:285
                    INFO     loading VAE from checkpoint                                                 sdxl_model_util.py:290
                    INFO     VAE: <All keys matched successfully>                                        sdxl_model_util.py:293
                    INFO     load VAE: stabilityai/sdxl-vae                                                  model_util.py:1267
                    INFO     additional VAE loaded                                                       sdxl_train_util.py:131
2025-08-02 17:33:17 INFO     [Dataset 0]                                                                     train_util.py:2613
                    INFO     caching latents with caching strategy.                                          train_util.py:1115
                    INFO     caching latents...                                                              train_util.py:1164
accelerator device: cuda
Disable Diffusers' xformers

  0%|          | 0/3 [00:00<?, ?it/s]
 67%|██████▋   | 2/3 [00:00<00:00,  2.61it/s]
100%|██████████| 3/3 [00:00<00:00,  3.92it/s]
2025-08-02 17:33:19 INFO     use Adafactor optimizer | {'scale_parameter': False, 'relative_step': False,    train_util.py:4963
                             'warmup_init': False, 'weight_decay': 0.01}                                                       
                    WARNING  constant_with_warmup will be good /                                             train_util.py:4995
                             スケジューラはconstant_with_warmupが良いかもしれません                                            
enable text encoder training
train unet: True, text_encoder1: True, text_encoder2: False
number of models: 2
number of trainable parameters: 2690524164
prepare optimizer, data loader etc.
override steps. steps for 2 epochs is / 指定エポックまでのステップ数: 90
enable full bf16 training.
running training / 学習開始
  num examples / サンプル数: 90
  num batches per epoch / 1epochのバッチ数: 45
  num epochs / epoch数: 2
  batch size per device / バッチサイズ: 2
  gradient accumulation steps / 勾配を合計するステップ数 = 1
  total optimization steps / 学習ステップ数: 90

steps:   0%|          | 0/90 [00:00<?, ?it/s]2025-08-02 17:33:20 INFO     epoch is incremented. current_epoch: 0, epoch: 1                                 train_util.py:779

steps:   1%|          | 1/90 [00:02<03:58,  2.68s/it]
steps:   1%|          | 1/90 [00:02<03:58,  2.68s/it, avr_loss=0.185]
steps:   2%|▏         | 2/90 [00:04<03:23,  2.31s/it, avr_loss=0.185]
steps:   2%|▏         | 2/90 [00:04<03:23,  2.32s/it, avr_loss=0.102]
steps:   3%|▎         | 3/90 [00:06<03:09,  2.18s/it, avr_loss=0.102]
steps:   3%|▎         | 3/90 [00:06<03:09,  2.18s/it, avr_loss=0.0998]
steps:   4%|▍         | 4/90 [00:08<03:12,  2.23s/it, avr_loss=0.0998]
steps:   4%|▍         | 4/90 [00:08<03:12,  2.23s/it, avr_loss=0.139] 
steps:   6%|▌         | 5/90 [00:11<03:08,  2.22s/it, avr_loss=0.139]
steps:   6%|▌         | 5/90 [00:11<03:08,  2.22s/it, avr_loss=0.133]
steps:   7%|▋         | 6/90 [00:12<03:01,  2.17s/it, avr_loss=0.133]
steps:   7%|▋         | 6/90 [00:12<03:01,  2.17s/it, avr_loss=0.114]
steps:   8%|▊         | 7/90 [00:14<02:56,  2.13s/it, avr_loss=0.114]
steps:   8%|▊         | 7/90 [00:14<02:57,  2.13s/it, avr_loss=0.13] 
steps:   9%|▉         | 8/90 [00:16<02:53,  2.11s/it, avr_loss=0.13]
steps:   9%|▉         | 8/90 [00:16<02:53,  2.11s/it, avr_loss=0.131]
steps:  10%|█         | 9/90 [00:18<02:49,  2.09s/it, avr_loss=0.131]
steps:  10%|█         | 9/90 [00:18<02:49,  2.09s/it, avr_loss=0.135]
steps:  11%|█         | 10/90 [00:20<02:47,  2.09s/it, avr_loss=0.135]
steps:  11%|█         | 10/90 [00:20<02:47,  2.09s/it, avr_loss=0.125]
steps:  12%|█▏        | 11/90 [00:22<02:44,  2.08s/it, avr_loss=0.125]
steps:  12%|█▏        | 11/90 [00:22<02:44,  2.08s/it, avr_loss=0.132]
steps:  13%|█▎        | 12/90 [00:25<02:43,  2.09s/it, avr_loss=0.132]
steps:  13%|█▎        | 12/90 [00:25<02:43,  2.09s/it, avr_loss=0.132]
steps:  14%|█▍        | 13/90 [00:26<02:39,  2.08s/it, avr_loss=0.132]
steps:  14%|█▍        | 13/90 [00:26<02:39,  2.08s/it, avr_loss=0.127]
steps:  16%|█▌        | 14/90 [00:28<02:36,  2.06s/it, avr_loss=0.127]
steps:  16%|█▌        | 14/90 [00:28<02:36,  2.07s/it, avr_loss=0.121]
steps:  17%|█▋        | 15/90 [00:30<02:34,  2.06s/it, avr_loss=0.121]
steps:  17%|█▋        | 15/90 [00:30<02:34,  2.06s/it, avr_loss=0.132]
steps:  18%|█▊        | 16/90 [00:32<02:31,  2.05s/it, avr_loss=0.132]
steps:  18%|█▊        | 16/90 [00:32<02:31,  2.05s/it, avr_loss=0.141]
steps:  19%|█▉        | 17/90 [00:34<02:29,  2.04s/it, avr_loss=0.141]
steps:  19%|█▉        | 17/90 [00:34<02:29,  2.04s/it, avr_loss=0.143]
steps:  20%|██        | 18/90 [00:36<02:26,  2.04s/it, avr_loss=0.143]
steps:  20%|██        | 18/90 [00:36<02:26,  2.04s/it, avr_loss=0.142]
steps:  21%|██        | 19/90 [00:38<02:24,  2.04s/it, avr_loss=0.142]
steps:  21%|██        | 19/90 [00:38<02:24,  2.04s/it, avr_loss=0.143]
steps:  22%|██▏       | 20/90 [00:40<02:22,  2.03s/it, avr_loss=0.143]
steps:  22%|██▏       | 20/90 [00:40<02:22,  2.03s/it, avr_loss=0.139]
steps:  23%|██▎       | 21/90 [00:42<02:19,  2.03s/it, avr_loss=0.139]
steps:  23%|██▎       | 21/90 [00:42<02:19,  2.03s/it, avr_loss=0.134]
steps:  24%|██▍       | 22/90 [00:44<02:17,  2.03s/it, avr_loss=0.134]
steps:  24%|██▍       | 22/90 [00:44<02:17,  2.03s/it, avr_loss=0.13] 
steps:  26%|██▌       | 23/90 [00:46<02:15,  2.02s/it, avr_loss=0.13]
steps:  26%|██▌       | 23/90 [00:46<02:15,  2.02s/it, avr_loss=0.132]
steps:  27%|██▋       | 24/90 [00:48<02:13,  2.02s/it, avr_loss=0.132]
steps:  27%|██▋       | 24/90 [00:48<02:13,  2.02s/it, avr_loss=0.132]
steps:  28%|██▊       | 25/90 [00:50<02:10,  2.01s/it, avr_loss=0.132]
steps:  28%|██▊       | 25/90 [00:50<02:10,  2.01s/it, avr_loss=0.135]
steps:  29%|██▉       | 26/90 [00:52<02:09,  2.02s/it, avr_loss=0.135]
steps:  29%|██▉       | 26/90 [00:52<02:09,  2.02s/it, avr_loss=0.136]
steps:  30%|███       | 27/90 [00:54<02:06,  2.01s/it, avr_loss=0.136]
steps:  30%|███       | 27/90 [00:54<02:06,  2.01s/it, avr_loss=0.134]
steps:  31%|███       | 28/90 [00:56<02:04,  2.01s/it, avr_loss=0.134]
steps:  31%|███       | 28/90 [00:56<02:04,  2.01s/it, avr_loss=0.131]
steps:  32%|███▏      | 29/90 [00:58<02:02,  2.01s/it, avr_loss=0.131]
steps:  32%|███▏      | 29/90 [00:58<02:02,  2.01s/it, avr_loss=0.137]
steps:  33%|███▎      | 30/90 [01:00<02:00,  2.01s/it, avr_loss=0.137]
steps:  33%|███▎      | 30/90 [01:00<02:00,  2.01s/it, avr_loss=0.138]
steps:  34%|███▍      | 31/90 [01:02<01:58,  2.00s/it, avr_loss=0.138]
steps:  34%|███▍      | 31/90 [01:02<01:58,  2.00s/it, avr_loss=0.136]
steps:  36%|███▌      | 32/90 [01:04<01:56,  2.00s/it, avr_loss=0.136]
steps:  36%|███▌      | 32/90 [01:04<01:56,  2.00s/it, avr_loss=0.136]
steps:  37%|███▋      | 33/90 [01:06<01:54,  2.01s/it, avr_loss=0.136]
steps:  37%|███▋      | 33/90 [01:06<01:54,  2.01s/it, avr_loss=0.135]
steps:  38%|███▊      | 34/90 [01:08<01:52,  2.01s/it, avr_loss=0.135]
steps:  38%|███▊      | 34/90 [01:08<01:52,  2.01s/it, avr_loss=0.151]
steps:  39%|███▉      | 35/90 [01:10<01:50,  2.01s/it, avr_loss=0.151]
steps:  39%|███▉      | 35/90 [01:10<01:50,  2.01s/it, avr_loss=0.147]
steps:  40%|████      | 36/90 [01:12<01:48,  2.01s/it, avr_loss=0.147]
steps:  40%|████      | 36/90 [01:12<01:48,  2.01s/it, avr_loss=0.144]
steps:  41%|████      | 37/90 [01:14<01:46,  2.00s/it, avr_loss=0.144]
steps:  41%|████      | 37/90 [01:14<01:46,  2.00s/it, avr_loss=0.14] 
steps:  42%|████▏     | 38/90 [01:16<01:44,  2.00s/it, avr_loss=0.14]
steps:  42%|████▏     | 38/90 [01:16<01:44,  2.00s/it, avr_loss=0.143]
steps:  43%|████▎     | 39/90 [01:17<01:41,  2.00s/it, avr_loss=0.143]
steps:  43%|████▎     | 39/90 [01:17<01:41,  2.00s/it, avr_loss=0.144]
steps:  44%|████▍     | 40/90 [01:19<01:39,  2.00s/it, avr_loss=0.144]
steps:  44%|████▍     | 40/90 [01:19<01:39,  2.00s/it, avr_loss=0.147]
steps:  46%|████▌     | 41/90 [01:21<01:37,  1.99s/it, avr_loss=0.147]
steps:  46%|████▌     | 41/90 [01:21<01:37,  1.99s/it, avr_loss=0.147]
steps:  47%|████▋     | 42/90 [01:23<01:35,  1.99s/it, avr_loss=0.147]
steps:  47%|████▋     | 42/90 [01:23<01:35,  1.99s/it, avr_loss=0.148]
steps:  48%|████▊     | 43/90 [01:25<01:33,  1.99s/it, avr_loss=0.148]
steps:  48%|████▊     | 43/90 [01:25<01:33,  1.99s/it, avr_loss=0.149]
steps:  49%|████▉     | 44/90 [01:27<01:31,  1.99s/it, avr_loss=0.149]
steps:  49%|████▉     | 44/90 [01:27<01:31,  1.99s/it, avr_loss=0.15] 
steps:  50%|█████     | 45/90 [01:29<01:29,  1.99s/it, avr_loss=0.15]
steps:  50%|█████     | 45/90 [01:29<01:29,  1.99s/it, avr_loss=0.147]2025-08-02 17:34:49 INFO     epoch is incremented. current_epoch: 1, epoch: 2                                 train_util.py:779

steps:  51%|█████     | 46/90 [01:31<01:27,  1.98s/it, avr_loss=0.147]
steps:  51%|█████     | 46/90 [01:31<01:27,  1.98s/it, avr_loss=0.149]
steps:  52%|█████▏    | 47/90 [01:33<01:25,  1.98s/it, avr_loss=0.149]
steps:  52%|█████▏    | 47/90 [01:33<01:25,  1.98s/it, avr_loss=0.152]
steps:  53%|█████▎    | 48/90 [01:35<01:23,  1.99s/it, avr_loss=0.152]
steps:  53%|█████▎    | 48/90 [01:35<01:23,  1.99s/it, avr_loss=0.152]
steps:  54%|█████▍    | 49/90 [01:37<01:21,  1.99s/it, avr_loss=0.152]
steps:  54%|█████▍    | 49/90 [01:37<01:21,  1.99s/it, avr_loss=0.147]
steps:  56%|█████▌    | 50/90 [01:39<01:19,  2.00s/it, avr_loss=0.147]
steps:  56%|█████▌    | 50/90 [01:39<01:19,  2.00s/it, avr_loss=0.148]
steps:  57%|█████▋    | 51/90 [01:41<01:17,  1.99s/it, avr_loss=0.148]
steps:  57%|█████▋    | 51/90 [01:41<01:17,  1.99s/it, avr_loss=0.149]
steps:  58%|█████▊    | 52/90 [01:43<01:15,  1.99s/it, avr_loss=0.149]
steps:  58%|█████▊    | 52/90 [01:43<01:15,  1.99s/it, avr_loss=0.147]
steps:  59%|█████▉    | 53/90 [01:45<01:13,  1.99s/it, avr_loss=0.147]
steps:  59%|█████▉    | 53/90 [01:45<01:13,  1.99s/it, avr_loss=0.145]
steps:  60%|██████    | 54/90 [01:47<01:11,  1.99s/it, avr_loss=0.145]
steps:  60%|██████    | 54/90 [01:47<01:11,  1.99s/it, avr_loss=0.146]
steps:  61%|██████    | 55/90 [01:49<01:09,  1.99s/it, avr_loss=0.146]
steps:  61%|██████    | 55/90 [01:49<01:09,  1.99s/it, avr_loss=0.146]
steps:  62%|██████▏   | 56/90 [01:51<01:07,  1.99s/it, avr_loss=0.146]
steps:  62%|██████▏   | 56/90 [01:51<01:07,  1.99s/it, avr_loss=0.144]
steps:  63%|██████▎   | 57/90 [01:53<01:05,  1.99s/it, avr_loss=0.144]
steps:  63%|██████▎   | 57/90 [01:53<01:05,  1.99s/it, avr_loss=0.146]
steps:  64%|██████▍   | 58/90 [01:55<01:03,  1.99s/it, avr_loss=0.146]
steps:  64%|██████▍   | 58/90 [01:55<01:03,  1.99s/it, avr_loss=0.151]
steps:  66%|██████▌   | 59/90 [01:57<01:01,  1.99s/it, avr_loss=0.151]
steps:  66%|██████▌   | 59/90 [01:57<01:01,  1.99s/it, avr_loss=0.157]
steps:  67%|██████▋   | 60/90 [01:59<00:59,  1.99s/it, avr_loss=0.157]
steps:  67%|██████▋   | 60/90 [01:59<00:59,  1.99s/it, avr_loss=0.155]
steps:  68%|██████▊   | 61/90 [02:01<00:57,  1.99s/it, avr_loss=0.155]
steps:  68%|██████▊   | 61/90 [02:01<00:57,  1.99s/it, avr_loss=0.153]
steps:  69%|██████▉   | 62/90 [02:03<00:55,  1.99s/it, avr_loss=0.153]
steps:  69%|██████▉   | 62/90 [02:03<00:55,  1.99s/it, avr_loss=0.151]
steps:  70%|███████   | 63/90 [02:05<00:53,  1.99s/it, avr_loss=0.151]
steps:  70%|███████   | 63/90 [02:05<00:53,  1.99s/it, avr_loss=0.149]
steps:  71%|███████   | 64/90 [02:07<00:51,  1.99s/it, avr_loss=0.149]
steps:  71%|███████   | 64/90 [02:07<00:51,  1.99s/it, avr_loss=0.146]
steps:  72%|███████▏  | 65/90 [02:09<00:49,  1.99s/it, avr_loss=0.146]
steps:  72%|███████▏  | 65/90 [02:09<00:49,  1.99s/it, avr_loss=0.146]
steps:  73%|███████▎  | 66/90 [02:11<00:47,  1.99s/it, avr_loss=0.146]
steps:  73%|███████▎  | 66/90 [02:11<00:47,  1.99s/it, avr_loss=0.148]
steps:  74%|███████▍  | 67/90 [02:12<00:45,  1.98s/it, avr_loss=0.148]
steps:  74%|███████▍  | 67/90 [02:12<00:45,  1.98s/it, avr_loss=0.151]
steps:  76%|███████▌  | 68/90 [02:15<00:43,  1.99s/it, avr_loss=0.151]
steps:  76%|███████▌  | 68/90 [02:15<00:43,  1.99s/it, avr_loss=0.151]
steps:  77%|███████▋  | 69/90 [02:17<00:41,  1.99s/it, avr_loss=0.151]
steps:  77%|███████▋  | 69/90 [02:17<00:41,  1.99s/it, avr_loss=0.149]
steps:  78%|███████▊  | 70/90 [02:19<00:39,  1.99s/it, avr_loss=0.149]
steps:  78%|███████▊  | 70/90 [02:19<00:39,  1.99s/it, avr_loss=0.145]
steps:  79%|███████▉  | 71/90 [02:21<00:37,  1.99s/it, avr_loss=0.145]
steps:  79%|███████▉  | 71/90 [02:21<00:37,  2.00s/it, avr_loss=0.142]
steps:  80%|████████  | 72/90 [02:24<00:36,  2.01s/it, avr_loss=0.142]
steps:  80%|████████  | 72/90 [02:24<00:36,  2.01s/it, avr_loss=0.14] 
steps:  81%|████████  | 73/90 [02:26<00:34,  2.00s/it, avr_loss=0.14]
steps:  81%|████████  | 73/90 [02:26<00:34,  2.00s/it, avr_loss=0.14]
steps:  82%|████████▏ | 74/90 [02:28<00:32,  2.00s/it, avr_loss=0.14]
steps:  82%|████████▏ | 74/90 [02:28<00:32,  2.00s/it, avr_loss=0.136]
steps:  83%|████████▎ | 75/90 [02:30<00:30,  2.00s/it, avr_loss=0.136]
steps:  83%|████████▎ | 75/90 [02:30<00:30,  2.00s/it, avr_loss=0.136]
steps:  84%|████████▍ | 76/90 [02:32<00:28,  2.00s/it, avr_loss=0.136]
steps:  84%|████████▍ | 76/90 [02:32<00:28,  2.00s/it, avr_loss=0.138]
steps:  86%|████████▌ | 77/90 [02:33<00:25,  2.00s/it, avr_loss=0.138]
steps:  86%|████████▌ | 77/90 [02:33<00:25,  2.00s/it, avr_loss=0.137]
steps:  87%|████████▋ | 78/90 [02:35<00:23,  2.00s/it, avr_loss=0.137]
steps:  87%|████████▋ | 78/90 [02:35<00:23,  2.00s/it, avr_loss=0.135]
steps:  88%|████████▊ | 79/90 [02:37<00:21,  2.00s/it, avr_loss=0.135]
steps:  88%|████████▊ | 79/90 [02:37<00:21,  2.00s/it, avr_loss=0.125]
steps:  89%|████████▉ | 80/90 [02:39<00:19,  2.00s/it, avr_loss=0.125]
steps:  89%|████████▉ | 80/90 [02:39<00:19,  2.00s/it, avr_loss=0.125]
steps:  90%|█████████ | 81/90 [02:41<00:17,  2.00s/it, avr_loss=0.125]
steps:  90%|█████████ | 81/90 [02:41<00:17,  2.00s/it, avr_loss=0.128]
steps:  91%|█████████ | 82/90 [02:43<00:15,  2.00s/it, avr_loss=0.128]
steps:  91%|█████████ | 82/90 [02:43<00:15,  2.00s/it, avr_loss=0.132]
steps:  92%|█████████▏| 83/90 [02:45<00:13,  1.99s/it, avr_loss=0.132]
steps:  92%|█████████▏| 83/90 [02:45<00:13,  1.99s/it, avr_loss=0.129]
steps:  93%|█████████▎| 84/90 [02:47<00:11,  1.99s/it, avr_loss=0.129]
steps:  93%|█████████▎| 84/90 [02:47<00:11,  1.99s/it, avr_loss=0.13] 
steps:  94%|█████████▍| 85/90 [02:49<00:09,  1.99s/it, avr_loss=0.13]
steps:  94%|█████████▍| 85/90 [02:49<00:09,  1.99s/it, avr_loss=0.127]
steps:  96%|█████████▌| 86/90 [02:51<00:07,  1.99s/it, avr_loss=0.127]
steps:  96%|█████████▌| 86/90 [02:51<00:07,  1.99s/it, avr_loss=0.126]
steps:  97%|█████████▋| 87/90 [02:53<00:05,  1.99s/it, avr_loss=0.126]
steps:  97%|█████████▋| 87/90 [02:53<00:05,  1.99s/it, avr_loss=0.129]
steps:  98%|█████████▊| 88/90 [02:54<00:03,  1.99s/it, avr_loss=0.129]
steps:  98%|█████████▊| 88/90 [02:54<00:03,  1.99s/it, avr_loss=0.128]
steps:  99%|█████████▉| 89/90 [02:56<00:01,  1.99s/it, avr_loss=0.128]
steps:  99%|█████████▉| 89/90 [02:56<00:01,  1.99s/it, avr_loss=0.124]
steps: 100%|██████████| 90/90 [02:58<00:00,  1.98s/it, avr_loss=0.124]
steps: 100%|██████████| 90/90 [02:58<00:00,  1.98s/it, avr_loss=0.128]2025-08-02 17:36:18 INFO     save trained model as StableDiffusion checkpoint to                             train_util.py:5952
                             /home/eqx/AutoTrainX/workspace/output/m14w00dh4ll/model/m14w00dh4ll_SX1_1e0ccca                   
                             c.safetensors                                                                                     
2025-08-02 17:36:30 INFO     model saved.                                                                     sdxl_train.py:888

steps: 100%|██████████| 90/90 [03:10<00:00,  2.11s/it, avr_loss=0.128]

epoch 1/2

epoch 2/2

# An√°lisis de Migraci√≥n de SQLite a PostgreSQL - AutoTrainX

## Resumen Ejecutivo

La migraci√≥n de SQLite a PostgreSQL en el sistema AutoTrainX es **t√©cnicamente viable** pero presenta una **complejidad moderada-alta**. El sistema utiliza caracter√≠sticas avanzadas de SQLite y patrones espec√≠ficos que requerir√°n refactorizaci√≥n cuidadosa.

**Veredicto:** Viable pero requiere esfuerzo considerable (3-4 semanas de desarrollo)

---

## 1. Estructura de Base de Datos Actual

### 1.1 Bases de Datos SQLite
- **executions.db** (144 KB) - Base de datos principal de seguimiento
- **dataset_paths.db** (16 KB) - Gesti√≥n de rutas de datasets

### 1.2 Esquema Principal

#### Tabla: executions
```sql
job_id VARCHAR(8) PRIMARY KEY
status VARCHAR(50) NOT NULL
pipeline_mode VARCHAR(20) NOT NULL
dataset_name VARCHAR(255) NOT NULL
preset VARCHAR(100) NOT NULL
total_steps INTEGER
start_time DATETIME
end_time DATETIME
duration_seconds FLOAT
success BOOLEAN
error_message TEXT
output_path TEXT
created_at DATETIME
updated_at DATETIME
```

#### Tabla: variations
```sql
job_id VARCHAR(8) PRIMARY KEY
status VARCHAR(50) NOT NULL
variation_id VARCHAR(100) NOT NULL
experiment_name VARCHAR(255) NOT NULL
dataset_name VARCHAR(255) NOT NULL
preset VARCHAR(100) NOT NULL
total_steps INTEGER
total_combinations INTEGER NOT NULL
varied_parameters TEXT NOT NULL -- JSON
parameter_values TEXT NOT NULL -- JSON
start_time DATETIME
end_time DATETIME
duration_seconds FLOAT
success BOOLEAN
error_message TEXT
output_path TEXT
parent_experiment_id VARCHAR(100)
created_at DATETIME
updated_at DATETIME
```

### 1.3 Caracter√≠sticas SQLite Utilizadas

#### Optimizaciones de Rendimiento
- **WAL Mode** (Write-Ahead Logging) para concurrencia
- **PRAGMA** statements para configuraci√≥n
- **√çndices compuestos** optimizados
- **Cache de 64MB** configurado
- **Auto-vacuum incremental**

#### Caracter√≠sticas Espec√≠ficas
- **AUTOINCREMENT** en claves primarias
- **JSON almacenado como TEXT**
- **sqlite_master** para introspecci√≥n
- **PRAGMA table_info()** para esquema din√°mico

---

## 2. An√°lisis de Complejidad de Migraci√≥n

### 2.1 Elementos de Baja Complejidad ‚úÖ

#### Esquema B√°sico
- Tablas simples con tipos de datos est√°ndar
- √çndices traducibles directamente a PostgreSQL
- Constraints b√°sicos (PRIMARY KEY, NOT NULL, UNIQUE)

#### Migraciones Directas
```sql
-- SQLite
CREATE TABLE executions (
    job_id VARCHAR(8) PRIMARY KEY,
    status VARCHAR(50) NOT NULL
);

-- PostgreSQL (pr√°cticamente id√©ntico)
CREATE TABLE executions (
    job_id VARCHAR(8) PRIMARY KEY,
    status VARCHAR(50) NOT NULL
);
```

### 2.2 Elementos de Complejidad Media ‚ö†Ô∏è

#### 1. JSON Storage
**SQLite:** TEXT columns con JSON serializado
```python
varied_parameters = Column(Text)  # JSON string
# Acceso: json.loads(self.varied_parameters)
```

**PostgreSQL:** Tipo nativo JSONB
```python
varied_parameters = Column(JSONB)
# Acceso: self.varied_parameters (directo)
```

**Esfuerzo:** Modificar modelos y l√≥gica de acceso

#### 2. AUTOINCREMENT
**SQLite:**
```sql
id INTEGER PRIMARY KEY AUTOINCREMENT
```

**PostgreSQL:**
```sql
id SERIAL PRIMARY KEY
-- o
id INTEGER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY
```

#### 3. Datetime Handling
**SQLite:** Almacena como TEXT (ISO format)
**PostgreSQL:** Tipo nativo TIMESTAMP WITH TIME ZONE

### 2.3 Elementos de Alta Complejidad üî¥

#### 1. PRAGMA Statements y Configuraci√≥n
**SQLite:**
```python
conn.execute("PRAGMA journal_mode=WAL")
conn.execute("PRAGMA busy_timeout=5000")
conn.execute("PRAGMA synchronous=NORMAL")
conn.execute("PRAGMA cache_size=-64000")
```

**PostgreSQL:** Requiere configuraci√≥n diferente
- WAL est√° siempre activo
- Timeouts mediante `statement_timeout`
- Cache configurado en postgresql.conf
- Sincronizaci√≥n mediante `synchronous_commit`

#### 2. Connection Management
**Actual:** SQLite con `check_same_thread=False`
```python
create_engine(
    f"sqlite:///{db_path}",
    connect_args={"check_same_thread": False}
)
```

**PostgreSQL:** Pool de conexiones nativo
```python
create_engine(
    "postgresql://user:pass@host/db",
    pool_size=10,
    max_overflow=20
)
```

#### 3. Concurrencia y Bloqueos
**SQLite:** Database-level locking con retry logic
```python
@TransactionManager.with_retry(max_attempts=3, delay=0.1)
def update_execution_status(self, job_id: str, status: ExecutionStatus):
    # Retry on "database is locked" errors
```

**PostgreSQL:** Row-level locking, requiere diferente estrategia
```python
# PostgreSQL: SELECT ... FOR UPDATE
query = session.query(Execution).filter_by(job_id=job_id).with_for_update()
```

#### 4. Introspecci√≥n de Esquema
**SQLite:**
```python
cursor.execute("PRAGMA table_info(executions)")
cursor.execute("SELECT * FROM sqlite_master WHERE type='table'")
```

**PostgreSQL:**
```sql
SELECT column_name, data_type 
FROM information_schema.columns 
WHERE table_name = 'executions';
```

---

## 3. Arquitectura de Migraci√≥n Propuesta

### 3.1 Cambios en Database Manager

```python
# Nuevo: database_factory.py
class DatabaseFactory:
    @staticmethod
    def create_engine(db_type: str, config: dict):
        if db_type == "sqlite":
            return create_sqlite_engine(config)
        elif db_type == "postgresql":
            return create_postgresql_engine(config)
```

### 3.2 Abstracci√≥n de Caracter√≠sticas Espec√≠ficas

```python
# database_dialect.py
class DatabaseDialect(ABC):
    @abstractmethod
    def get_json_type(self):
        pass
    
    @abstractmethod
    def configure_connection(self, connection):
        pass

class SQLiteDialect(DatabaseDialect):
    def get_json_type(self):
        return Text
    
    def configure_connection(self, connection):
        connection.execute("PRAGMA journal_mode=WAL")

class PostgreSQLDialect(DatabaseDialect):
    def get_json_type(self):
        return JSONB
    
    def configure_connection(self, connection):
        connection.execute("SET statement_timeout = '5s'")
```

### 3.3 Modelos Adaptables

```python
# models.py
from sqlalchemy import Column, String, Integer
from sqlalchemy.dialects import postgresql, sqlite

class Execution(Base):
    __tablename__ = 'executions'
    
    job_id = Column(String(8), primary_key=True)
    
    # Tipo condicional seg√∫n dialecto
    varied_parameters = Column(
        postgresql.JSONB().with_variant(
            sqlite.TEXT(), 'sqlite'
        )
    )
```

---

## 4. Plan de Migraci√≥n Detallado

### Fase 1: Preparaci√≥n (1 semana)
1. **Crear capa de abstracci√≥n de base de datos**
   - Factory pattern para engines
   - Dialect abstraction para caracter√≠sticas espec√≠ficas
   - Configuraci√≥n dual SQLite/PostgreSQL

2. **Refactorizar modelos para compatibilidad dual**
   - Tipos de datos condicionales
   - M√©todos de acceso JSON abstractos
   - Timestamps con timezone awareness

### Fase 2: Implementaci√≥n (2 semanas)
1. **Adaptar Database Managers**
   - EnhancedDatabaseManager con soporte PostgreSQL
   - Connection pooling nativo de PostgreSQL
   - Transaction management adaptado

2. **Migrar caracter√≠sticas espec√≠ficas**
   - PRAGMA ‚Üí configuraci√≥n PostgreSQL
   - sqlite_master ‚Üí information_schema
   - Retry logic ‚Üí row-level locking

3. **Actualizar API endpoints**
   - dataset_paths.py para usar abstracci√≥n
   - Queries SQL raw a trav√©s de dialect

### Fase 3: Migraci√≥n de Datos (3-4 d√≠as)
1. **Herramienta de migraci√≥n**
```python
# migrate_to_postgresql.py
def migrate_database():
    # 1. Dump SQLite data
    sqlite_data = dump_sqlite_database()
    
    # 2. Transform data types
    transform_json_columns(sqlite_data)
    transform_timestamps(sqlite_data)
    
    # 3. Load into PostgreSQL
    load_postgresql_database(sqlite_data)
```

2. **Validaci√≥n de integridad**
   - Comparar row counts
   - Verificar JSON parsing
   - Validar √≠ndices y constraints

### Fase 4: Testing y Validaci√≥n (3-4 d√≠as)
1. **Suite de pruebas dual**
   - Tests parametrizados para ambas BD
   - Validaci√≥n de performance
   - Tests de concurrencia

2. **Migraci√≥n gradual**
   - Feature flag para cambiar BD
   - Monitoreo de ambas BD en paralelo
   - Rollback plan

---

## 5. Cambios Espec√≠ficos Requeridos

### 5.1 Archivos a Modificar

#### Alta Prioridad
- `/src/database/manager.py` - Abstracci√≥n completa
- `/src/database/enhanced_manager.py` - Soporte PostgreSQL
- `/src/database/models.py` - Tipos condicionales
- `/src/database/connection_pool.py` - Pool nativo PG
- `/api/routes/dataset_paths.py` - Eliminar sqlite3 directo

#### Media Prioridad
- `/src/database/schema_improvements.py` - Optimizaciones PG
- `/src/database/transactions.py` - Locking strategies
- Todos los archivos con PRAGMA statements

### 5.2 Nuevos Archivos Necesarios
```
/src/database/
‚îú‚îÄ‚îÄ dialects/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ base.py          # AbstractDialect
‚îÇ   ‚îú‚îÄ‚îÄ sqlite.py        # SQLiteDialect
‚îÇ   ‚îî‚îÄ‚îÄ postgresql.py    # PostgreSQLDialect
‚îú‚îÄ‚îÄ factory.py           # DatabaseFactory
‚îî‚îÄ‚îÄ migrations/
    ‚îî‚îÄ‚îÄ sqlite_to_pg.py  # Migration tool
```

---

## 6. Beneficios de la Migraci√≥n

### Performance
- **Mejor concurrencia** - Row-level locking
- **Queries m√°s eficientes** - Query planner avanzado
- **JSON nativo** - JSONB indexable y queryable

### Escalabilidad
- **Multi-usuario real** - Sin bloqueos de base de datos
- **Replicaci√≥n** - Master-slave, streaming replication
- **Particionamiento** - Para datos hist√≥ricos

### Features Avanzadas
- **Full-text search** nativo
- **Triggers y stored procedures**
- **Views materializadas** reales
- **Window functions** avanzadas

---

## 7. Riesgos y Mitigaciones

### Riesgos
1. **Complejidad de deployment** - Requiere servidor PostgreSQL
2. **Overhead de red** - Latencia vs archivo local
3. **Backup m√°s complejo** - No es solo copiar un archivo
4. **Curva de aprendizaje** - Administraci√≥n PostgreSQL

### Mitigaciones
1. **Docker compose** para desarrollo local
2. **Connection pooling** agresivo
3. **pg_dump automatizado** + WAL archiving
4. **Documentaci√≥n detallada** y runbooks

---

## 8. Estimaci√≥n de Esfuerzo

### Desarrollo
- **Abstracci√≥n y refactoring:** 5-7 d√≠as
- **Implementaci√≥n PostgreSQL:** 5-7 d√≠as
- **Herramientas de migraci√≥n:** 2-3 d√≠as
- **Testing exhaustivo:** 3-4 d√≠as
- **Documentaci√≥n:** 2 d√≠as

**Total:** 17-23 d√≠as laborables (3-4 semanas)

### Recursos Necesarios
- 1-2 desarrolladores senior con experiencia en:
  - SQLAlchemy avanzado
  - PostgreSQL administration
  - Python async/concurrency
- Infraestructura PostgreSQL para desarrollo/staging

---

## 9. Recomendaciones

### Si Migrar ‚úÖ
- Sistema en crecimiento con m√∫ltiples usuarios concurrentes
- Necesidad de queries complejos sobre JSON
- Requerimientos de alta disponibilidad
- Integraci√≥n con otras aplicaciones

### No Migrar ‚ùå
- Sistema single-user o pocos usuarios
- Deployment simple es prioritario
- No hay experiencia PostgreSQL en el equipo
- Funciona bien actualmente con SQLite

### Alternativa H√≠brida
Considerar mantener SQLite para:
- dataset_paths.db (simple, pocas escrituras)
- Desarrollo local y testing

Y migrar solo executions.db a PostgreSQL para producci√≥n.

---

## 10. Conclusi√≥n

La migraci√≥n es **t√©cnicamente viable** y traer√≠a beneficios significativos en performance y escalabilidad. Sin embargo, requiere un esfuerzo considerable debido a:

1. Uso extensivo de caracter√≠sticas SQLite espec√≠ficas
2. Necesidad de mantener compatibilidad dual
3. Cambios arquitecturales profundos

**Recomendaci√≥n:** Proceder con la migraci√≥n si hay planes de crecimiento significativo o problemas actuales de concurrencia. De lo contrario, SQLite sigue siendo una opci√≥n v√°lida para el caso de uso actual.